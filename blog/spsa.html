<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Using SPSA for optimizing Neural Networks - Anshul Yadav</title>
  <link rel="stylesheet" href="../styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
</head>
<body>
  <header>
    <div class="container">
      <h1>Anshul Yadav</h1>
      <nav>
        <ul>
          <li><a href="../index.html">Home</a></li>
          <li><a href="../blog.html">Blog</a></li>
          <!-- Add more navigation links as needed -->
        </ul>
      </nav>
    </div>
  </header>
  
  <main>
    <section id="post2" class="actual-post">
      <div class="container">
        <h2>Using SPSA for optimizing Neural Networks</h2>
        <p><strong>Date:</strong> June 21, 2019</p>
        
        <p>Neural Networks are at the core of deep learning. But these are often constrained by the Back-propagation algorithm, which requires the derivative of the Loss function with respect to network parameters. In this post, I will show that Neural Networks are not limited by back-propagation and we can use Simultaneous Perturbation using Stochastic Approximation (SPSA) to find noisy gradients.</p>
    
    <p>This technique is highly useful when it is very expensive to compute the gradients of the loss function or it is not differentiable at all. Gradient Descent or any other popular optimization algorithms like Adam/RMSProp require computing the Gradient.</p>
    
    <h2>Simultaneous Perturbation for Stochastic Perturbation (SPSA)</h2>
    <p>Let us formulate our optimization problem as:</p>
    <p>$$\hat{x} = \arg\min_x f(x)$$</p>
    <p>Gradient descent is a well-known optimization algorithm for finding the optimum in convex functions. It takes steps as:</p>
    <p>$$x_{t+1} = x_t - \epsilon \nabla f(x)$$</p>
    <p>Using the first principle of Calculus, this can be computed as:</p>
    <p>$$g(x) = \lim_{\epsilon \to 0} \frac{f(x+\epsilon) - f(x-\epsilon)}{2\epsilon}$$</p>
    <p>Now, SPSA takes advantage of the above equation and uses an approximated gradient:</p>
    <p>$$\hat{g}(x) = \frac{f(x+\delta) - f(x-\delta)}{2\delta}$$</p>
    <blockquote>
        <p>The reader must keep in mind that backpropagation is a bottom-to-top approach, whereas there is no such constraint on SPSA to update the network parameters. So, we often use a top-to-bottom approach while training using SPSA.</p>
    </blockquote>
    
    <h3>Pseudo Code for SPSA Update</h3>
    <pre><code>
    x_0 \in \mathbb{R}^m
    for t = 1 to t_{max}:
        set a_t = \frac{a}{t^\alpha}
        set c_t = \frac{c}{t^\gamma}
        randomly sample \delta \sim \mathcal{U}({−1, +1}^m)
        set x^+ = x_t + c_t \delta
        set x^- = x_t - c_t \delta
        compute \hat{g}(x_t) using:
            \hat{g}(x_t) = \frac{f(x^+) − f(x^-)}{2 c_t \delta}
        update:
            x_{t+1} = x_t − a_t * \hat{g}(x_t)
    </code></pre>
    
    <h3>Python Code</h3>
    <pre><code>
    def train(self, inputs, targets, num_epochs, t_max=200):
        weights = []
        np.random.seed(1)
        weights.append(np.random.randn(self.input_dim, self.output_dim))
        
        for epoch in range(num_epochs):
            for l in range(len(weights)):
                W_p = np.copy(weights)
                W_m = np.copy(weights)
                for t in range(1, t_max):
                    a_t = self.a / t**self.alpha
                    c_t = self.c / t**self.gamma
                    delta = np.random.binomial(1, 0.5, size=weights[l].shape) * 2. - 1
                    W_p[l] += c_t * delta
                    loss_p = self.loss(self.forward(inputs, W_p), targets)
                    W_m[l] -= c_t * delta
                    loss_m = self.loss(self.forward(inputs, W_m), targets)
                    g_hat = (loss_p - loss_m) / (2 * c_t * delta)
                    weights[l] -= a_t * g_hat
            if epoch % 1 == 0:
                print("RMSE Loss is: ", np.sum((self.forward(inputs, weights) - targets)**2))
        return weights
    </code></pre>
    
    <h3>References</h3>
    <p>[Slides of Christian Bauckhage on using SPSA for solving Neural Networks](https://www.researchgate.net/profile/Christian_Bauckhage/project/lectures-on-pattern-recognition/attachment/5a5c9cf14cde266d58831886/AS:583039802462208@1516018929842/download/lecture-18-add-on-2.pdf?context=ProjectUpdatesLog)</p>
    
      </div>
    </section>
  </main>
  
 <footer>
    <div class="container">
      <p>&copy; 2024 Anshul Yadav. All rights reserved.</p>
      <div class="social-icons">
        <a href="https://www.linkedin.com/in/anshul-yadav-iitd/" target="_blank" rel="noopener"><i class="fab fa-linkedin"></i></a>
        <a href="https://github.com/ay1141982112" target="_blank" rel="noopener"><i class="fab fa-github"></i></a>
        <a href="https://twitter.com/ay1141982112" target="_blank" rel="noopener"><i class="fab fa-twitter"></i></a>
        <a href="https://www.instagram.com/ay1141982112" target="_blank" rel="noopener"><i class="fab fa-instagram"></i></a>
        
    </div>
  </footer>

</body>
</html>
